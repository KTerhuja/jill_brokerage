{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('../data/filtered_actuals.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FiscalYear</th>\n",
       "      <th>Armstrong, Brooke</th>\n",
       "      <th>Breen, Daniel</th>\n",
       "      <th>Cosby, Russell</th>\n",
       "      <th>Curry, Ashley</th>\n",
       "      <th>Darrow, Terry</th>\n",
       "      <th>Eckert, Jeff</th>\n",
       "      <th>Esquivel, James</th>\n",
       "      <th>Forkner, Fiona</th>\n",
       "      <th>Haggar, James</th>\n",
       "      <th>...</th>\n",
       "      <th>Selner, Bradley</th>\n",
       "      <th>Sheehy, Ahnie</th>\n",
       "      <th>Shipley, Christopher</th>\n",
       "      <th>Smith, Jubal</th>\n",
       "      <th>Stout, Christopher</th>\n",
       "      <th>Taguwa, Andrew</th>\n",
       "      <th>Toon, Larry</th>\n",
       "      <th>Weatherby, Samuel</th>\n",
       "      <th>Whitman, Paul</th>\n",
       "      <th>Wood, Alan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>1380583.55</td>\n",
       "      <td>171398.16</td>\n",
       "      <td>770342.33</td>\n",
       "      <td>88839.39</td>\n",
       "      <td>1003383.83</td>\n",
       "      <td>750000.05</td>\n",
       "      <td>750000.01</td>\n",
       "      <td>384698.30</td>\n",
       "      <td>301113.55</td>\n",
       "      <td>...</td>\n",
       "      <td>3188933.63</td>\n",
       "      <td>151.72</td>\n",
       "      <td>356160.84</td>\n",
       "      <td>1771504.76</td>\n",
       "      <td>102575.75</td>\n",
       "      <td>901100.59</td>\n",
       "      <td>2259899.50</td>\n",
       "      <td>637791.99</td>\n",
       "      <td>1562838.05</td>\n",
       "      <td>856670.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>631544.09</td>\n",
       "      <td>2194829.40</td>\n",
       "      <td>463416.90</td>\n",
       "      <td>335981.55</td>\n",
       "      <td>815760.82</td>\n",
       "      <td>997785.67</td>\n",
       "      <td>997785.62</td>\n",
       "      <td>998910.44</td>\n",
       "      <td>525300.89</td>\n",
       "      <td>...</td>\n",
       "      <td>2209823.93</td>\n",
       "      <td>142877.89</td>\n",
       "      <td>633904.48</td>\n",
       "      <td>7359378.40</td>\n",
       "      <td>250876.09</td>\n",
       "      <td>1011467.41</td>\n",
       "      <td>983978.26</td>\n",
       "      <td>1043269.72</td>\n",
       "      <td>1997295.13</td>\n",
       "      <td>786498.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>1125976.16</td>\n",
       "      <td>1492879.42</td>\n",
       "      <td>1897362.90</td>\n",
       "      <td>401767.00</td>\n",
       "      <td>360931.29</td>\n",
       "      <td>995381.26</td>\n",
       "      <td>990905.52</td>\n",
       "      <td>1301178.85</td>\n",
       "      <td>641300.49</td>\n",
       "      <td>...</td>\n",
       "      <td>2076925.86</td>\n",
       "      <td>218536.00</td>\n",
       "      <td>808734.66</td>\n",
       "      <td>2113433.76</td>\n",
       "      <td>439799.56</td>\n",
       "      <td>714371.11</td>\n",
       "      <td>68855.76</td>\n",
       "      <td>576363.95</td>\n",
       "      <td>1207541.71</td>\n",
       "      <td>608604.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>1526556.11</td>\n",
       "      <td>2425068.14</td>\n",
       "      <td>216952.35</td>\n",
       "      <td>267907.45</td>\n",
       "      <td>588227.17</td>\n",
       "      <td>812467.24</td>\n",
       "      <td>807640.25</td>\n",
       "      <td>665690.49</td>\n",
       "      <td>533198.91</td>\n",
       "      <td>...</td>\n",
       "      <td>2135517.42</td>\n",
       "      <td>333502.62</td>\n",
       "      <td>1325188.67</td>\n",
       "      <td>1495679.59</td>\n",
       "      <td>439281.72</td>\n",
       "      <td>998930.30</td>\n",
       "      <td>7801514.26</td>\n",
       "      <td>683077.75</td>\n",
       "      <td>363890.00</td>\n",
       "      <td>626262.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>1786851.61</td>\n",
       "      <td>1557403.06</td>\n",
       "      <td>1035997.29</td>\n",
       "      <td>506123.66</td>\n",
       "      <td>429284.82</td>\n",
       "      <td>939797.56</td>\n",
       "      <td>939452.24</td>\n",
       "      <td>701267.31</td>\n",
       "      <td>540839.62</td>\n",
       "      <td>...</td>\n",
       "      <td>837927.59</td>\n",
       "      <td>394708.13</td>\n",
       "      <td>1221506.39</td>\n",
       "      <td>1477429.31</td>\n",
       "      <td>439691.67</td>\n",
       "      <td>1171395.37</td>\n",
       "      <td>543049.64</td>\n",
       "      <td>1662274.72</td>\n",
       "      <td>947842.79</td>\n",
       "      <td>433940.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019</td>\n",
       "      <td>2927638.63</td>\n",
       "      <td>1966813.19</td>\n",
       "      <td>2630950.86</td>\n",
       "      <td>393480.17</td>\n",
       "      <td>500000.00</td>\n",
       "      <td>610360.97</td>\n",
       "      <td>610355.66</td>\n",
       "      <td>589002.22</td>\n",
       "      <td>776827.65</td>\n",
       "      <td>...</td>\n",
       "      <td>3435213.05</td>\n",
       "      <td>500000.00</td>\n",
       "      <td>875584.42</td>\n",
       "      <td>9027557.98</td>\n",
       "      <td>837256.10</td>\n",
       "      <td>500000.00</td>\n",
       "      <td>563242.34</td>\n",
       "      <td>542493.41</td>\n",
       "      <td>798450.78</td>\n",
       "      <td>676387.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020</td>\n",
       "      <td>2774229.05</td>\n",
       "      <td>694513.79</td>\n",
       "      <td>85726.02</td>\n",
       "      <td>226290.45</td>\n",
       "      <td>69027.42</td>\n",
       "      <td>555576.34</td>\n",
       "      <td>555576.49</td>\n",
       "      <td>585002.05</td>\n",
       "      <td>765932.58</td>\n",
       "      <td>...</td>\n",
       "      <td>5020462.00</td>\n",
       "      <td>303459.66</td>\n",
       "      <td>1030727.50</td>\n",
       "      <td>1858116.40</td>\n",
       "      <td>729262.65</td>\n",
       "      <td>826222.42</td>\n",
       "      <td>204838.14</td>\n",
       "      <td>128476.25</td>\n",
       "      <td>1288304.98</td>\n",
       "      <td>92353.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021</td>\n",
       "      <td>1521039.35</td>\n",
       "      <td>1176575.40</td>\n",
       "      <td>1734397.73</td>\n",
       "      <td>529705.03</td>\n",
       "      <td>890021.64</td>\n",
       "      <td>1162108.21</td>\n",
       "      <td>1121160.16</td>\n",
       "      <td>334546.52</td>\n",
       "      <td>293815.62</td>\n",
       "      <td>...</td>\n",
       "      <td>3908492.32</td>\n",
       "      <td>217530.65</td>\n",
       "      <td>1382872.15</td>\n",
       "      <td>4769175.02</td>\n",
       "      <td>888623.37</td>\n",
       "      <td>650988.56</td>\n",
       "      <td>3920452.28</td>\n",
       "      <td>513034.18</td>\n",
       "      <td>1154146.70</td>\n",
       "      <td>273606.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022</td>\n",
       "      <td>138760.99</td>\n",
       "      <td>243170.51</td>\n",
       "      <td>262885.16</td>\n",
       "      <td>557611.48</td>\n",
       "      <td>240795.18</td>\n",
       "      <td>1101099.99</td>\n",
       "      <td>1071926.24</td>\n",
       "      <td>750000.00</td>\n",
       "      <td>1310808.71</td>\n",
       "      <td>...</td>\n",
       "      <td>4545074.40</td>\n",
       "      <td>488972.28</td>\n",
       "      <td>3319633.14</td>\n",
       "      <td>584342.95</td>\n",
       "      <td>900358.85</td>\n",
       "      <td>1277070.87</td>\n",
       "      <td>26433.64</td>\n",
       "      <td>559862.94</td>\n",
       "      <td>363262.31</td>\n",
       "      <td>500000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023</td>\n",
       "      <td>-10737.07</td>\n",
       "      <td>427007.70</td>\n",
       "      <td>15142.76</td>\n",
       "      <td>592223.29</td>\n",
       "      <td>9041.67</td>\n",
       "      <td>986421.71</td>\n",
       "      <td>846948.54</td>\n",
       "      <td>1319272.27</td>\n",
       "      <td>2250000.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2703434.77</td>\n",
       "      <td>126778.85</td>\n",
       "      <td>1530226.11</td>\n",
       "      <td>758521.60</td>\n",
       "      <td>1331616.06</td>\n",
       "      <td>1417720.02</td>\n",
       "      <td>26137.89</td>\n",
       "      <td>1128375.68</td>\n",
       "      <td>334568.10</td>\n",
       "      <td>180236.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FiscalYear  Armstrong, Brooke  Breen, Daniel  Cosby, Russell  \\\n",
       "0        2014         1380583.55      171398.16       770342.33   \n",
       "1        2015          631544.09     2194829.40       463416.90   \n",
       "2        2016         1125976.16     1492879.42      1897362.90   \n",
       "3        2017         1526556.11     2425068.14       216952.35   \n",
       "4        2018         1786851.61     1557403.06      1035997.29   \n",
       "5        2019         2927638.63     1966813.19      2630950.86   \n",
       "6        2020         2774229.05      694513.79        85726.02   \n",
       "7        2021         1521039.35     1176575.40      1734397.73   \n",
       "8        2022          138760.99      243170.51       262885.16   \n",
       "9        2023          -10737.07      427007.70        15142.76   \n",
       "\n",
       "   Curry, Ashley  Darrow, Terry  Eckert, Jeff  Esquivel, James  \\\n",
       "0       88839.39     1003383.83     750000.05        750000.01   \n",
       "1      335981.55      815760.82     997785.67        997785.62   \n",
       "2      401767.00      360931.29     995381.26        990905.52   \n",
       "3      267907.45      588227.17     812467.24        807640.25   \n",
       "4      506123.66      429284.82     939797.56        939452.24   \n",
       "5      393480.17      500000.00     610360.97        610355.66   \n",
       "6      226290.45       69027.42     555576.34        555576.49   \n",
       "7      529705.03      890021.64    1162108.21       1121160.16   \n",
       "8      557611.48      240795.18    1101099.99       1071926.24   \n",
       "9      592223.29        9041.67     986421.71        846948.54   \n",
       "\n",
       "   Forkner, Fiona  Haggar, James  ...  Selner, Bradley  Sheehy, Ahnie  \\\n",
       "0       384698.30      301113.55  ...       3188933.63         151.72   \n",
       "1       998910.44      525300.89  ...       2209823.93      142877.89   \n",
       "2      1301178.85      641300.49  ...       2076925.86      218536.00   \n",
       "3       665690.49      533198.91  ...       2135517.42      333502.62   \n",
       "4       701267.31      540839.62  ...        837927.59      394708.13   \n",
       "5       589002.22      776827.65  ...       3435213.05      500000.00   \n",
       "6       585002.05      765932.58  ...       5020462.00      303459.66   \n",
       "7       334546.52      293815.62  ...       3908492.32      217530.65   \n",
       "8       750000.00     1310808.71  ...       4545074.40      488972.28   \n",
       "9      1319272.27     2250000.00  ...       2703434.77      126778.85   \n",
       "\n",
       "   Shipley, Christopher  Smith, Jubal  Stout, Christopher  Taguwa, Andrew  \\\n",
       "0             356160.84    1771504.76           102575.75       901100.59   \n",
       "1             633904.48    7359378.40           250876.09      1011467.41   \n",
       "2             808734.66    2113433.76           439799.56       714371.11   \n",
       "3            1325188.67    1495679.59           439281.72       998930.30   \n",
       "4            1221506.39    1477429.31           439691.67      1171395.37   \n",
       "5             875584.42    9027557.98           837256.10       500000.00   \n",
       "6            1030727.50    1858116.40           729262.65       826222.42   \n",
       "7            1382872.15    4769175.02           888623.37       650988.56   \n",
       "8            3319633.14     584342.95           900358.85      1277070.87   \n",
       "9            1530226.11     758521.60          1331616.06      1417720.02   \n",
       "\n",
       "   Toon, Larry  Weatherby, Samuel  Whitman, Paul  Wood, Alan  \n",
       "0   2259899.50          637791.99     1562838.05   856670.45  \n",
       "1    983978.26         1043269.72     1997295.13   786498.94  \n",
       "2     68855.76          576363.95     1207541.71   608604.08  \n",
       "3   7801514.26          683077.75      363890.00   626262.49  \n",
       "4    543049.64         1662274.72      947842.79   433940.03  \n",
       "5    563242.34          542493.41      798450.78   676387.34  \n",
       "6    204838.14          128476.25     1288304.98    92353.73  \n",
       "7   3920452.28          513034.18     1154146.70   273606.92  \n",
       "8     26433.64          559862.94      363262.31   500000.00  \n",
       "9     26137.89         1128375.68      334568.10   180236.10  \n",
       "\n",
       "[10 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_broker_target = pd.read_excel('../data/Actualandtarget_1401_10.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "broker_list = data.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_broker_target_pivot = pd.pivot_table(data = data_broker_target, columns='FiscalYear', index='Broker', values='BrokerTarget').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>FiscalYear</th>\n",
       "      <th>Broker</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Algrim, Phillip</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>850000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Altman, Cribb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andrew, Megan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>755000.0</td>\n",
       "      <td>900000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angelle, Tiffany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>3780000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ankenbrand, Kimarie</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Williams, Michael</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>335000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Wood, Alan</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>2400000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>955000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Wood, Jeff</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>540000.0</td>\n",
       "      <td>670000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Wright, Chris</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>1120000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>garner, michael</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3720000.0</td>\n",
       "      <td>3780000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "FiscalYear               Broker      2014      2015       2016      2017  \\\n",
       "0               Algrim, Phillip  700000.0  850000.0        NaN       NaN   \n",
       "1                 Altman, Cribb       NaN       NaN        NaN       NaN   \n",
       "2                 Andrew, Megan       NaN       NaN        NaN       NaN   \n",
       "3              Angelle, Tiffany       NaN       NaN        NaN       NaN   \n",
       "4           Ankenbrand, Kimarie  750000.0  500000.0  1600000.0  500000.0   \n",
       "..                          ...       ...       ...        ...       ...   \n",
       "118           Williams, Michael       NaN       NaN        NaN       NaN   \n",
       "119                  Wood, Alan  600000.0  750000.0   800000.0  800000.0   \n",
       "120                  Wood, Jeff       NaN       NaN        NaN       NaN   \n",
       "121               Wright, Chris       NaN       NaN        NaN       NaN   \n",
       "122             garner, michael       NaN       NaN        NaN       NaN   \n",
       "\n",
       "FiscalYear       2018      2019      2020       2021       2022       2023  \n",
       "0                 NaN       NaN       NaN        NaN        NaN        NaN  \n",
       "1                 NaN       NaN       NaN        NaN        NaN  5000000.0  \n",
       "2                 NaN       NaN       NaN        NaN   755000.0   900000.0  \n",
       "3                 NaN       NaN       NaN        NaN   750000.0  3780000.0  \n",
       "4            750000.0  600000.0  600000.0        NaN        NaN        NaN  \n",
       "..                ...       ...       ...        ...        ...        ...  \n",
       "118               NaN       NaN       NaN   300000.0   270000.0   335000.0  \n",
       "119         2400000.0       NaN  800000.0        NaN        NaN   955000.0  \n",
       "120               NaN       NaN       NaN   500000.0   540000.0   670000.0  \n",
       "121               NaN       NaN       NaN  1600000.0   900000.0  1120000.0  \n",
       "122               NaN       NaN       NaN        NaN  3720000.0  3780000.0  \n",
       "\n",
       "[123 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_broker_target_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_broker_target_pivot_filtered = data_broker_target_pivot[data_broker_target_pivot['Broker'].isin(broker_list)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_broker_target_pivot_filtered_transposed = data_broker_target_pivot_filtered.set_index('Broker').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Broker</th>\n",
       "      <th>Armstrong, Brooke</th>\n",
       "      <th>Breen, Daniel</th>\n",
       "      <th>Cosby, Russell</th>\n",
       "      <th>Curry, Ashley</th>\n",
       "      <th>Darrow, Terry</th>\n",
       "      <th>Eckert, Jeff</th>\n",
       "      <th>Esquivel, James</th>\n",
       "      <th>Forkner, Fiona</th>\n",
       "      <th>Haggar, James</th>\n",
       "      <th>Halstedt, Lauren</th>\n",
       "      <th>...</th>\n",
       "      <th>Selner, Bradley</th>\n",
       "      <th>Sheehy, Ahnie</th>\n",
       "      <th>Shipley, Christopher</th>\n",
       "      <th>Smith, Jubal</th>\n",
       "      <th>Stout, Christopher</th>\n",
       "      <th>Taguwa, Andrew</th>\n",
       "      <th>Toon, Larry</th>\n",
       "      <th>Weatherby, Samuel</th>\n",
       "      <th>Whitman, Paul</th>\n",
       "      <th>Wood, Alan</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FiscalYear</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>1200000.0</td>\n",
       "      <td>500000.00</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2100000.0</td>\n",
       "      <td>1400000.0</td>\n",
       "      <td>1400000.0</td>\n",
       "      <td>1300000.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1750000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>600000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1250000.0</td>\n",
       "      <td>500000.00</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>855000.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>750000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1500000.00</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>1400000.0</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>966667.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2200000.0</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>966667.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>1633334.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>750000.0</td>\n",
       "      <td>1379000.00</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>8650000.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1250000.0</td>\n",
       "      <td>2218666.67</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>2400000.0</td>\n",
       "      <td>2400000.0</td>\n",
       "      <td>2250000.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1750000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>1800000.0</td>\n",
       "      <td>2218666.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>850000.0</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>2400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>2500000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1800000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>550000.0</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1290000.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1090000.0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>1630000.0</td>\n",
       "      <td>1630000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>1265000.0</td>\n",
       "      <td>1540000.0</td>\n",
       "      <td>1260000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1540000.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1360000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1020000.0</td>\n",
       "      <td>2040000.0</td>\n",
       "      <td>1910000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2550000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>2160000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>955000.0</td>\n",
       "      <td>640000.0</td>\n",
       "      <td>955000.0</td>\n",
       "      <td>955000.0</td>\n",
       "      <td>955000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Broker      Armstrong, Brooke  Breen, Daniel  Cosby, Russell  Curry, Ashley  \\\n",
       "FiscalYear                                                                    \n",
       "2014                1200000.0      500000.00       1000000.0            NaN   \n",
       "2015                1250000.0      500000.00       2000000.0       150000.0   \n",
       "2016                1000000.0     1500000.00       1500000.0       400000.0   \n",
       "2017                 750000.0     1379000.00       1000000.0       400000.0   \n",
       "2018                1250000.0     2218666.67       1000000.0       400000.0   \n",
       "2019                      NaN            NaN             NaN            NaN   \n",
       "2020                2500000.0            NaN       2000000.0            NaN   \n",
       "2021                      NaN            NaN             NaN      1500000.0   \n",
       "2022                      NaN     1290000.00             NaN      1090000.0   \n",
       "2023                      NaN     1540000.00             NaN      1360000.0   \n",
       "\n",
       "Broker      Darrow, Terry  Eckert, Jeff  Esquivel, James  Forkner, Fiona  \\\n",
       "FiscalYear                                                                 \n",
       "2014            2100000.0     1400000.0        1400000.0       1300000.0   \n",
       "2015            1600000.0     1600000.0        1600000.0       1500000.0   \n",
       "2016            1400000.0      700000.0         700000.0        966667.0   \n",
       "2017             400000.0      800000.0         800000.0        750000.0   \n",
       "2018             700000.0     2400000.0        2400000.0       2250000.0   \n",
       "2019                  NaN           NaN              NaN             NaN   \n",
       "2020                  NaN           NaN              NaN       1800000.0   \n",
       "2021                  NaN           NaN         700000.0             NaN   \n",
       "2022             315000.0     1630000.0        1630000.0             NaN   \n",
       "2023                  NaN     1020000.0        2040000.0       1910000.0   \n",
       "\n",
       "Broker      Haggar, James  Halstedt, Lauren  ...  Selner, Bradley  \\\n",
       "FiscalYear                                   ...                    \n",
       "2014             350000.0               NaN  ...        1750000.0   \n",
       "2015            1200000.0          125000.0  ...        2500000.0   \n",
       "2016             600000.0          200000.0  ...        2200000.0   \n",
       "2017            1500000.0          300000.0  ...        2000000.0   \n",
       "2018            1000000.0               NaN  ...        1750000.0   \n",
       "2019                  NaN               NaN  ...              NaN   \n",
       "2020                  NaN               NaN  ...        2500000.0   \n",
       "2021                  NaN          200000.0  ...              NaN   \n",
       "2022            1250000.0          360000.0  ...              NaN   \n",
       "2023                  NaN          445000.0  ...        2550000.0   \n",
       "\n",
       "Broker      Sheehy, Ahnie  Shipley, Christopher  Smith, Jubal  \\\n",
       "FiscalYear                                                      \n",
       "2014                  NaN              400000.0     1200000.0   \n",
       "2015              75000.0              400000.0     2500000.0   \n",
       "2016             160000.0              500000.0     3000000.0   \n",
       "2017             200000.0              750000.0     1500000.0   \n",
       "2018             200000.0             1800000.0     2218666.0   \n",
       "2019                  NaN                   NaN           NaN   \n",
       "2020                  NaN                   NaN           NaN   \n",
       "2021             500000.0             2000000.0           NaN   \n",
       "2022             900000.0             1265000.0     1540000.0   \n",
       "2023                  NaN             1575000.0     2160000.0   \n",
       "\n",
       "Broker      Stout, Christopher  Taguwa, Andrew  Toon, Larry  \\\n",
       "FiscalYear                                                    \n",
       "2014                  200000.0        750000.0    1500000.0   \n",
       "2015                  250000.0        855000.0    1500000.0   \n",
       "2016                  500000.0        966667.0    1500000.0   \n",
       "2017                  400000.0        750000.0    8650000.0   \n",
       "2018                 1200000.0       1000000.0    2000000.0   \n",
       "2019                       NaN             NaN          NaN   \n",
       "2020                       NaN       2000000.0     600000.0   \n",
       "2021                       NaN             NaN          NaN   \n",
       "2022                 1260000.0             NaN          NaN   \n",
       "2023                       NaN        955000.0     640000.0   \n",
       "\n",
       "Broker      Weatherby, Samuel  Whitman, Paul  Wood, Alan  \n",
       "FiscalYear                                                \n",
       "2014                 500000.0      1500000.0    600000.0  \n",
       "2015                 600000.0      1500000.0    750000.0  \n",
       "2016                1633334.0      1500000.0    800000.0  \n",
       "2017                 600000.0      1000000.0    800000.0  \n",
       "2018                 850000.0      3000000.0   2400000.0  \n",
       "2019                      NaN            NaN         NaN  \n",
       "2020                 550000.0       800000.0    800000.0  \n",
       "2021                      NaN            NaN         NaN  \n",
       "2022                      NaN            NaN         NaN  \n",
       "2023                 955000.0       955000.0    955000.0  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_broker_target_pivot_filtered_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_broker_target_pivot_filtered_transposed = data_broker_target_pivot_filtered_transposed.reset_index().rename(columns= {'index':'FiscalYear'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index().rename(columns= {'index':'FiscalYear'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_broker_target_pivot_filtered_transposed['FiscalYear'] = pd.to_datetime(data_broker_target_pivot_filtered_transposed['FiscalYear'], format = \"%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Time'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Time'"
     ]
    }
   ],
   "source": [
    "data['Time'] = pd.to_datetime(data['Time'], format = \"%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in data.columns[1:]:\n",
    "    model = ARIMA(data[name], order=(2, 1, 3))\n",
    "    model_fit = model.fit()\n",
    "    data[name] = data[name].fillna(model_fit.predict(start=0, end=len(data)-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/home/codespace/.local/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for ARMA and trend. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n"
     ]
    }
   ],
   "source": [
    "for name in data_broker_target_pivot_filtered_transposed.columns[1:]:\n",
    "    model = ARIMA(data_broker_target_pivot_filtered_transposed[name], order=(2, 1, 3))\n",
    "    model_fit = model.fit()\n",
    "    data_broker_target_pivot_filtered_transposed[name] = data_broker_target_pivot_filtered_transposed[name].fillna(model_fit.predict(start=0, end=len(data_broker_target_pivot_filtered_transposed)-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_broker_target_pivot_filtered_transposed.to_excel('../data/filtered_broker_target_filledna.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Broker</th>\n",
       "      <th>FiscalYear</th>\n",
       "      <th>Armstrong, Brooke</th>\n",
       "      <th>Breen, Daniel</th>\n",
       "      <th>Cosby, Russell</th>\n",
       "      <th>Curry, Ashley</th>\n",
       "      <th>Darrow, Terry</th>\n",
       "      <th>Eckert, Jeff</th>\n",
       "      <th>Esquivel, James</th>\n",
       "      <th>Forkner, Fiona</th>\n",
       "      <th>Haggar, James</th>\n",
       "      <th>...</th>\n",
       "      <th>Selner, Bradley</th>\n",
       "      <th>Sheehy, Ahnie</th>\n",
       "      <th>Shipley, Christopher</th>\n",
       "      <th>Smith, Jubal</th>\n",
       "      <th>Stout, Christopher</th>\n",
       "      <th>Taguwa, Andrew</th>\n",
       "      <th>Toon, Larry</th>\n",
       "      <th>Weatherby, Samuel</th>\n",
       "      <th>Whitman, Paul</th>\n",
       "      <th>Wood, Alan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>5.000000e+05</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.100000e+06</td>\n",
       "      <td>1.400000e+06</td>\n",
       "      <td>1.400000e+06</td>\n",
       "      <td>1.300000e+06</td>\n",
       "      <td>3.500000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.750000e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>7.500000e+05</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>5.000000e+05</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>6.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>1.250000e+06</td>\n",
       "      <td>5.000000e+05</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>1.500000e+05</td>\n",
       "      <td>1.600000e+06</td>\n",
       "      <td>1.600000e+06</td>\n",
       "      <td>1.600000e+06</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>2.500000e+05</td>\n",
       "      <td>8.550000e+05</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>6.000000e+05</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>7.500000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>1.400000e+06</td>\n",
       "      <td>7.000000e+05</td>\n",
       "      <td>7.000000e+05</td>\n",
       "      <td>9.666670e+05</td>\n",
       "      <td>6.000000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.200000e+06</td>\n",
       "      <td>1.600000e+05</td>\n",
       "      <td>5.000000e+05</td>\n",
       "      <td>3.000000e+06</td>\n",
       "      <td>5.000000e+05</td>\n",
       "      <td>9.666670e+05</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>1.633334e+06</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>8.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>7.500000e+05</td>\n",
       "      <td>1.379000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>8.000000e+05</td>\n",
       "      <td>8.000000e+05</td>\n",
       "      <td>7.500000e+05</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>7.500000e+05</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>7.500000e+05</td>\n",
       "      <td>8.650000e+06</td>\n",
       "      <td>6.000000e+05</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>8.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1.250000e+06</td>\n",
       "      <td>2.218667e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>4.000000e+05</td>\n",
       "      <td>7.000000e+05</td>\n",
       "      <td>2.400000e+06</td>\n",
       "      <td>2.400000e+06</td>\n",
       "      <td>2.250000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.750000e+06</td>\n",
       "      <td>2.000000e+05</td>\n",
       "      <td>1.800000e+06</td>\n",
       "      <td>2.218666e+06</td>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>1.000000e+06</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>8.500000e+05</td>\n",
       "      <td>3.000000e+06</td>\n",
       "      <td>2.400000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1.797766e+06</td>\n",
       "      <td>1.977076e+06</td>\n",
       "      <td>1.515785e+06</td>\n",
       "      <td>4.450111e+05</td>\n",
       "      <td>7.050786e+05</td>\n",
       "      <td>1.501899e+06</td>\n",
       "      <td>2.555989e+06</td>\n",
       "      <td>2.119291e+06</td>\n",
       "      <td>1.417596e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.808278e+06</td>\n",
       "      <td>1.751064e+05</td>\n",
       "      <td>1.351294e+06</td>\n",
       "      <td>2.574303e+06</td>\n",
       "      <td>6.214291e+05</td>\n",
       "      <td>1.108331e+06</td>\n",
       "      <td>5.171692e+06</td>\n",
       "      <td>4.640914e+05</td>\n",
       "      <td>1.229895e+06</td>\n",
       "      <td>1.685388e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>2.347287e+06</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>3.514417e+05</td>\n",
       "      <td>8.218090e+05</td>\n",
       "      <td>7.387744e+05</td>\n",
       "      <td>1.489310e+06</td>\n",
       "      <td>1.800000e+06</td>\n",
       "      <td>1.232599e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>1.438106e+05</td>\n",
       "      <td>1.642270e+06</td>\n",
       "      <td>2.405552e+06</td>\n",
       "      <td>1.397253e+06</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>6.000000e+05</td>\n",
       "      <td>5.500000e+05</td>\n",
       "      <td>8.000000e+05</td>\n",
       "      <td>8.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2.122976e+06</td>\n",
       "      <td>2.188235e+06</td>\n",
       "      <td>1.713554e+06</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>8.277283e+05</td>\n",
       "      <td>1.580360e+06</td>\n",
       "      <td>7.000000e+05</td>\n",
       "      <td>1.735445e+06</td>\n",
       "      <td>1.382997e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.770005e+06</td>\n",
       "      <td>5.000000e+05</td>\n",
       "      <td>2.000000e+06</td>\n",
       "      <td>1.564799e+06</td>\n",
       "      <td>8.762097e+05</td>\n",
       "      <td>2.161284e+06</td>\n",
       "      <td>2.934364e+06</td>\n",
       "      <td>5.351797e+05</td>\n",
       "      <td>1.899507e+06</td>\n",
       "      <td>2.567850e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>1.633932e+06</td>\n",
       "      <td>1.290000e+06</td>\n",
       "      <td>1.241154e+06</td>\n",
       "      <td>1.090000e+06</td>\n",
       "      <td>3.150000e+05</td>\n",
       "      <td>1.630000e+06</td>\n",
       "      <td>1.630000e+06</td>\n",
       "      <td>2.168313e+06</td>\n",
       "      <td>1.250000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.728648e+06</td>\n",
       "      <td>9.000000e+05</td>\n",
       "      <td>1.265000e+06</td>\n",
       "      <td>1.540000e+06</td>\n",
       "      <td>1.260000e+06</td>\n",
       "      <td>2.010360e+06</td>\n",
       "      <td>2.911698e+06</td>\n",
       "      <td>5.808094e+05</td>\n",
       "      <td>1.636898e+06</td>\n",
       "      <td>1.696021e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>1.697376e+06</td>\n",
       "      <td>1.540000e+06</td>\n",
       "      <td>1.229080e+06</td>\n",
       "      <td>1.360000e+06</td>\n",
       "      <td>4.605749e+05</td>\n",
       "      <td>1.020000e+06</td>\n",
       "      <td>2.040000e+06</td>\n",
       "      <td>1.910000e+06</td>\n",
       "      <td>1.322577e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.550000e+06</td>\n",
       "      <td>1.267266e+06</td>\n",
       "      <td>1.575000e+06</td>\n",
       "      <td>2.160000e+06</td>\n",
       "      <td>8.151310e+05</td>\n",
       "      <td>9.550000e+05</td>\n",
       "      <td>6.400000e+05</td>\n",
       "      <td>9.550000e+05</td>\n",
       "      <td>9.550000e+05</td>\n",
       "      <td>9.550000e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Broker FiscalYear  Armstrong, Brooke  Breen, Daniel  Cosby, Russell  \\\n",
       "0      2014-01-01       1.200000e+06   5.000000e+05    1.000000e+06   \n",
       "1      2015-01-01       1.250000e+06   5.000000e+05    2.000000e+06   \n",
       "2      2016-01-01       1.000000e+06   1.500000e+06    1.500000e+06   \n",
       "3      2017-01-01       7.500000e+05   1.379000e+06    1.000000e+06   \n",
       "4      2018-01-01       1.250000e+06   2.218667e+06    1.000000e+06   \n",
       "5      2019-01-01       1.797766e+06   1.977076e+06    1.515785e+06   \n",
       "6      2020-01-01       2.500000e+06   2.347287e+06    2.000000e+06   \n",
       "7      2021-01-01       2.122976e+06   2.188235e+06    1.713554e+06   \n",
       "8      2022-01-01       1.633932e+06   1.290000e+06    1.241154e+06   \n",
       "9      2023-01-01       1.697376e+06   1.540000e+06    1.229080e+06   \n",
       "\n",
       "Broker  Curry, Ashley  Darrow, Terry  Eckert, Jeff  Esquivel, James  \\\n",
       "0        0.000000e+00   2.100000e+06  1.400000e+06     1.400000e+06   \n",
       "1        1.500000e+05   1.600000e+06  1.600000e+06     1.600000e+06   \n",
       "2        4.000000e+05   1.400000e+06  7.000000e+05     7.000000e+05   \n",
       "3        4.000000e+05   4.000000e+05  8.000000e+05     8.000000e+05   \n",
       "4        4.000000e+05   7.000000e+05  2.400000e+06     2.400000e+06   \n",
       "5        4.450111e+05   7.050786e+05  1.501899e+06     2.555989e+06   \n",
       "6        3.514417e+05   8.218090e+05  7.387744e+05     1.489310e+06   \n",
       "7        1.500000e+06   8.277283e+05  1.580360e+06     7.000000e+05   \n",
       "8        1.090000e+06   3.150000e+05  1.630000e+06     1.630000e+06   \n",
       "9        1.360000e+06   4.605749e+05  1.020000e+06     2.040000e+06   \n",
       "\n",
       "Broker  Forkner, Fiona  Haggar, James  ...  Selner, Bradley  Sheehy, Ahnie  \\\n",
       "0         1.300000e+06   3.500000e+05  ...     1.750000e+06   0.000000e+00   \n",
       "1         1.500000e+06   1.200000e+06  ...     2.500000e+06   7.500000e+04   \n",
       "2         9.666670e+05   6.000000e+05  ...     2.200000e+06   1.600000e+05   \n",
       "3         7.500000e+05   1.500000e+06  ...     2.000000e+06   2.000000e+05   \n",
       "4         2.250000e+06   1.000000e+06  ...     1.750000e+06   2.000000e+05   \n",
       "5         2.119291e+06   1.417596e+06  ...     1.808278e+06   1.751064e+05   \n",
       "6         1.800000e+06   1.232599e+06  ...     2.500000e+06   1.438106e+05   \n",
       "7         1.735445e+06   1.382997e+06  ...     2.770005e+06   5.000000e+05   \n",
       "8         2.168313e+06   1.250000e+06  ...     2.728648e+06   9.000000e+05   \n",
       "9         1.910000e+06   1.322577e+06  ...     2.550000e+06   1.267266e+06   \n",
       "\n",
       "Broker  Shipley, Christopher  Smith, Jubal  Stout, Christopher  \\\n",
       "0               4.000000e+05  1.200000e+06        2.000000e+05   \n",
       "1               4.000000e+05  2.500000e+06        2.500000e+05   \n",
       "2               5.000000e+05  3.000000e+06        5.000000e+05   \n",
       "3               7.500000e+05  1.500000e+06        4.000000e+05   \n",
       "4               1.800000e+06  2.218666e+06        1.200000e+06   \n",
       "5               1.351294e+06  2.574303e+06        6.214291e+05   \n",
       "6               1.642270e+06  2.405552e+06        1.397253e+06   \n",
       "7               2.000000e+06  1.564799e+06        8.762097e+05   \n",
       "8               1.265000e+06  1.540000e+06        1.260000e+06   \n",
       "9               1.575000e+06  2.160000e+06        8.151310e+05   \n",
       "\n",
       "Broker  Taguwa, Andrew   Toon, Larry  Weatherby, Samuel  Whitman, Paul  \\\n",
       "0         7.500000e+05  1.500000e+06       5.000000e+05   1.500000e+06   \n",
       "1         8.550000e+05  1.500000e+06       6.000000e+05   1.500000e+06   \n",
       "2         9.666670e+05  1.500000e+06       1.633334e+06   1.500000e+06   \n",
       "3         7.500000e+05  8.650000e+06       6.000000e+05   1.000000e+06   \n",
       "4         1.000000e+06  2.000000e+06       8.500000e+05   3.000000e+06   \n",
       "5         1.108331e+06  5.171692e+06       4.640914e+05   1.229895e+06   \n",
       "6         2.000000e+06  6.000000e+05       5.500000e+05   8.000000e+05   \n",
       "7         2.161284e+06  2.934364e+06       5.351797e+05   1.899507e+06   \n",
       "8         2.010360e+06  2.911698e+06       5.808094e+05   1.636898e+06   \n",
       "9         9.550000e+05  6.400000e+05       9.550000e+05   9.550000e+05   \n",
       "\n",
       "Broker    Wood, Alan  \n",
       "0       6.000000e+05  \n",
       "1       7.500000e+05  \n",
       "2       8.000000e+05  \n",
       "3       8.000000e+05  \n",
       "4       2.400000e+06  \n",
       "5       1.685388e+06  \n",
       "6       8.000000e+05  \n",
       "7       2.567850e+06  \n",
       "8       1.696021e+06  \n",
       "9       9.550000e+05  \n",
       "\n",
       "[10 rows x 34 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_broker_target_pivot_filtered_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['FiscalYear'] = pd.to_datetime(data['FiscalYear'], format=\"%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('../data/filtered_filledna.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.metrics.metrics import rmse\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.models import RNNModel, ExponentialSmoothing, BlockRNNModel, NBEATSModel, RandomForest, NHiTSModel, NaiveMovingAverage, XGBModel, CatBoostModel\n",
    "from darts.utils.utils import ModelMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_year = '2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = TimeSeries.from_dataframe(data, time_col=\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series, val_series = series.split_before(pd.Timestamp(cutoff_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(name, training_scaled, validation_scaled):\n",
    "\n",
    "    score = {}\n",
    "\n",
    "    # baseline \n",
    "    moving_average = NaiveMovingAverage(input_chunk_length=3)\n",
    "    moving_average.fit(training_scaled[name])\n",
    "    prediction = moving_average.predict(2024 - int(cutoff_year))\n",
    "\n",
    "    moving_average_score = rmse(validation_scaled[name], prediction)\n",
    "    score[\"MovingAverage\"] = moving_average_score\n",
    "\n",
    "    # statistical \n",
    "    es = ExponentialSmoothing(trend=ModelMode.ADDITIVE, seasonal=None)\n",
    "    es.fit(training_scaled[name])\n",
    "    prediction = es.predict(2024 - int(cutoff_year))\n",
    "\n",
    "\n",
    "    es_score = rmse(validation_scaled[name], prediction)\n",
    "    score[\"ExponentialSmoothing\"] = es_score\n",
    "\n",
    "\n",
    "    # ml\n",
    "    rf = RandomForest(lags=1, n_estimators=10)\n",
    "    rf.fit(training_scaled[name])\n",
    "    prediction = rf.predict(2024 - int(cutoff_year))\n",
    "    rf_score = rmse(validation_scaled[name], prediction)\n",
    "    \n",
    "    score[\"RandomForest\"] = rf_score\n",
    "\n",
    "    cb = CatBoostModel(lags=1, n_estimators=10)\n",
    "    cb.fit(training_scaled[name])\n",
    "    prediction = rf.predict(2024 - int(cutoff_year))\n",
    "    cb_score = rmse(validation_scaled[name], prediction)\n",
    "    \n",
    "    score[\"CatBoost\"] = cb_score\n",
    "\n",
    "    xgb = XGBModel(lags=1, n_estimators=10)\n",
    "    xgb.fit(training_scaled[name])\n",
    "    prediction = xgb.predict(2024 - int(cutoff_year))\n",
    "    xgb_score = rmse(validation_scaled[name], prediction)\n",
    "    \n",
    "    score[\"XGBModel\"] = xgb_score\n",
    "\n",
    "    # dl\n",
    "\n",
    "    nhits = NHiTSModel(\n",
    "    input_chunk_length=3,\n",
    "    output_chunk_length=4,\n",
    "    num_blocks=2,\n",
    "    n_epochs=5,\n",
    ")\n",
    "    nhits.fit(training_scaled[name])\n",
    "    prediction = nhits.predict(2024 - int(cutoff_year))\n",
    "    nhits_score = rmse(validation_scaled[name], prediction)\n",
    "    score[\"NHiTS\"] = nhits_score\n",
    "\n",
    "\n",
    "    return score\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.55it/s, train_loss=0.164]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 36.35it/s, train_loss=0.164]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.07it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 36.31it/s, train_loss=0.117] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 33.95it/s, train_loss=0.117]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.45it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 37.94it/s, train_loss=0.109] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 35.76it/s, train_loss=0.109]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.27it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 29.23it/s, train_loss=0.100] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 27.96it/s, train_loss=0.100]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.78it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.80it/s, train_loss=0.115]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 36.64it/s, train_loss=0.115]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.79it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.40it/s, train_loss=0.0785]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 36.20it/s, train_loss=0.0785]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.10it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.92it/s, train_loss=0.0936]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 36.75it/s, train_loss=0.0936]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.36it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 40.11it/s, train_loss=0.107] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 37.06it/s, train_loss=0.107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.35it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 29.33it/s, train_loss=0.275] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 27.42it/s, train_loss=0.275]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 113.45it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 28.74it/s, train_loss=0.0488]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 26.60it/s, train_loss=0.0488]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.87it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.13it/s, train_loss=0.0767]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 36.06it/s, train_loss=0.0767]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.68it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.90it/s, train_loss=0.117] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 36.66it/s, train_loss=0.117]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.71it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.15it/s, train_loss=0.223] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 35.34it/s, train_loss=0.223]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.48it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 37.12it/s, train_loss=0.117] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 35.29it/s, train_loss=0.117]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.33it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.51it/s, train_loss=0.0542]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 36.35it/s, train_loss=0.0542]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 37.85it/s, train_loss=0.0604]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 35.79it/s, train_loss=0.0604]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.12it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.15it/s, train_loss=0.152] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 36.03it/s, train_loss=0.152]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 40.56it/s, train_loss=0.0663]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.07it/s, train_loss=0.0663]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.81it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.85it/s, train_loss=0.142] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 36.42it/s, train_loss=0.142]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 29.17it/s, train_loss=0.0338]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 27.48it/s, train_loss=0.0338]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.14it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 27.56it/s, train_loss=0.00631]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 25.88it/s, train_loss=0.00631]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 160.70it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.15it/s, train_loss=0.109] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 36.04it/s, train_loss=0.109]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.34it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.71it/s, train_loss=0.112]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 36.52it/s, train_loss=0.112]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.66it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 41.03it/s, train_loss=0.165]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.43it/s, train_loss=0.165]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.46it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 37.41it/s, train_loss=0.158] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 35.35it/s, train_loss=0.158]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.34it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 40.54it/s, train_loss=0.0424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 37.28it/s, train_loss=0.0424]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.15it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 35.08it/s, train_loss=0.084]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 31.97it/s, train_loss=0.084]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 139.17it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.12it/s, train_loss=0.081]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 35.89it/s, train_loss=0.081]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 40.08it/s, train_loss=0.106] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 37.67it/s, train_loss=0.106]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.52it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 39.67it/s, train_loss=0.126] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 37.44it/s, train_loss=0.126]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 129.82it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 40.09it/s, train_loss=0.0645]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 37.73it/s, train_loss=0.0645]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.27it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 32.56it/s, train_loss=0.0358]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 29.84it/s, train_loss=0.0358]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.77it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 37.10it/s, train_loss=0.0557]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 34.68it/s, train_loss=0.0557]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.70it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 41.40it/s, train_loss=0.0994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.95it/s, train_loss=0.0994]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.46it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 39.37it/s, train_loss=0.232] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 37.16it/s, train_loss=0.232]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 155.33it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 39.40it/s, train_loss=0.261] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 36.67it/s, train_loss=0.261]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.07it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 27.08it/s, train_loss=0.131] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 22.46it/s, train_loss=0.131]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 155.25it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | criterion       | MSELoss          | 0      | train\n",
      "1 | train_criterion | MSELoss          | 0      | train\n",
      "2 | val_criterion   | MSELoss          | 0      | train\n",
      "3 | train_metrics   | MetricCollection | 0      | train\n",
      "4 | val_metrics     | MetricCollection | 0      | train\n",
      "5 | stacks          | ModuleList       | 1.6 M  | train\n",
      "-------------------------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "1.5 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.423     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 38.11it/s, train_loss=0.0773]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00, 35.98it/s, train_loss=0.0773]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.47it/s]\n"
     ]
    }
   ],
   "source": [
    "moving_average_list = []\n",
    "exponential_smoothing_list = []\n",
    "rf_list = []\n",
    "nhits_list = []\n",
    "xgb_list = []\n",
    "catboost_list = []\n",
    "for name in data.columns[1:]:\n",
    "\n",
    "    scaler = Scaler()\n",
    "    training_scaled = scaler.fit_transform(train_series[name])\n",
    "    validation_scaled = scaler.transform(val_series[name])\n",
    "    scores = get_score(name, training_scaled, validation_scaled)\n",
    "\n",
    "    moving_average_list.append(scores['MovingAverage'])\n",
    "    exponential_smoothing_list.append(scores['ExponentialSmoothing'])\n",
    "    rf_list.append(scores['RandomForest'])\n",
    "    nhits_list.append(scores['NHiTS'])\n",
    "    xgb_list.append(scores['XGBModel'])\n",
    "    catboost_list.append(scores['CatBoost'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the aveage score of moving average is 0.512\n",
      "the aveage score of exponential Smoothing is 0.651\n",
      "the aveage score of random forest is 0.535\n",
      "the aveage score of nhits is 0.779\n",
      "the average score of catboost is 0.535\n",
      "the average score of xgboost is 0.573\n"
     ]
    }
   ],
   "source": [
    "print(f\"the aveage score of moving average is {round(sum(moving_average_list)/len(moving_average_list),3)}\")\n",
    "print(f\"the aveage score of exponential Smoothing is {round(sum(exponential_smoothing_list)/len(exponential_smoothing_list),3)}\")\n",
    "print(f\"the aveage score of random forest is {round(sum(rf_list)/len(rf_list),3)}\")\n",
    "print(f\"the aveage score of nhits is {round(sum(nhits_list)/len(nhits_list),3)}\")\n",
    "print(f\"the average score of catboost is {round(sum(catboost_list)/len(catboost_list),3)}\")\n",
    "print(f\"the average score of xgboost is {round(sum(xgb_list)/len(xgb_list),3)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
